{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hm3_pt1",
      "provenance": [],
      "authorship_tag": "ABX9TyN3c5AzsuFKPhw8/ZHi5hUq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jenyav94/Component_Extracting/blob/master/hm3_pt1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this link won't work for you, if you want to generate working link, \n",
        "# visit https://askubuntu.com/questions/1188381/how-to-get-link-of-file-to-download-with-wget\n",
        "# or download the data and place it to folder manually\n",
        "! wget \"https://downloader.disk.yandex.ru/disk/76973f058fe726659fa4ccc755e901552e300ab50b78634dab78a9799a22b1a2/6283c701/aZ8Akc9CqtcaAMvg9MkExUmNfU9U_vPugtmtwAC7LCh7Ob4GqD-JrqJl2rsy_hxC-1lho6HNKGxRJzyaqhvCBg%3D%3D?uid=0&filename=celebA_train_500.zip&disposition=attachment&hash=PKVHlR%2B3q03Ys8aOKp5s/dgbI1MoVhGrKn/oCUbHWox44FxZCGQEdyLSePCIwi7Tq/J6bpmRyOJonT3VoXnDag%3D%3D%3A&limit=0&content_type=application%2Fzip&owner_uid=316082386&fsize=170342993&hid=8e5296bb80b8febc2b500d8fd890bbcf&media_type=compressed&tknv=v2\" -O celebA.zip\n",
        "! unzip celebA.zip"
      ],
      "metadata": {
        "id": "s3aVdFQx5OyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/timesler/facenet-pytorch.git\n",
        "! mv facenet-pytorch/models ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn8JCS-z5xu5",
        "outputId": "bc6f3086-450a-4bc1-e514-0c6dde4eace5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'facenet-pytorch'...\n",
            "remote: Enumerating objects: 1267, done.\u001b[K\n",
            "remote: Total 1267 (delta 0), reused 0 (delta 0), pack-reused 1267\u001b[K\n",
            "Receiving objects: 100% (1267/1267), 22.88 MiB | 43.39 MiB/s, done.\n",
            "Resolving deltas: 100% (620/620), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-metric-learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1euOhGNW1rt",
        "outputId": "df37b75c-fdc7-4496-9a1e-57c8598e0697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-metric-learning\n",
            "  Downloading pytorch_metric_learning-1.3.0-py3-none-any.whl (109 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 40 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 81 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 109 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.11.0+cu113)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-metric-learning) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-metric-learning) (7.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pytorch-metric-learning) (2.10)\n",
            "Installing collected packages: pytorch-metric-learning\n",
            "Successfully installed pytorch-metric-learning-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87_IOtjm4s77"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import tqdm\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_paths(dataset_type='train'):\n",
        "    '''\n",
        "    a function that returnes list of images paths for a given type of the dataset\n",
        "    params:\n",
        "      dataset_type: one of 'train', 'val', 'test'\n",
        "    '''\n",
        "\n",
        "    labels_dict = {\n",
        "        'train': 0,\n",
        "        'val': 1,\n",
        "        'test': 2,\n",
        "    }\n",
        "\n",
        "    f = open('celebA_train/celebA_train_split.txt', 'r')\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "\n",
        "    lines = [x.strip().split() for x in lines]\n",
        "    lines = [x[0] for x in lines if int(x[1]) == labels_dict[dataset_type]]\n",
        "\n",
        "    images_paths = []\n",
        "    for filename in lines:\n",
        "        images_paths.append(os.path.join('celebA_train/celebA_imgs/', filename))\n",
        "\n",
        "    return np.array(images_paths)\n",
        "\n",
        "\n",
        "class celebADataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset_type, transform, train=True):\n",
        "        self.images = get_paths(dataset_type=dataset_type)\n",
        "        self.is_train = train\n",
        "\n",
        "        f = open('celebA_train/celebA_anno.txt', 'r')\n",
        "        labels = f.readlines()\n",
        "        f.close()\n",
        "        labels = [x.strip().split() for x in labels]\n",
        "        labels = {x: y for x, y in labels}\n",
        "        self.labels = [int(labels[x.split('/')[-1]]) for x in self.images]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        anchor_name = self.images[idx]\n",
        "        anchor_label = self.labels[idx]\n",
        "        anchor_image = self.transform(Image.open(anchor_name))\n",
        "\n",
        "        if self.is_train:\n",
        "\n",
        "            positive_list = [name for i, name in enumerate(self.images)\n",
        "                             if self.labels[i] == anchor_label and\n",
        "                             name != anchor_name]\n",
        "            if len(positive_list) == 0:\n",
        "                positive_name = anchor_name\n",
        "            else:\n",
        "                positive_name = random.choice(positive_list)\n",
        "\n",
        "            negative_list = [name for i, name in enumerate(self.images) if self.labels[i] != anchor_label]\n",
        "            negative_name = random.choice(negative_list)\n",
        "\n",
        "            positive_image = self.transform(Image.open(positive_name))\n",
        "            negative_image = self.transform(Image.open(negative_name))\n",
        "\n",
        "            return anchor_image, positive_image, negative_image, anchor_label\n",
        "        else:\n",
        "            return anchor_image, anchor_label\n"
      ],
      "metadata": {
        "id": "z3bqAPT143DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "means = np.array((0.485, 0.456, 0.406))\n",
        "stds = np.array((0.229, 0.224, 0.225))\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # you may add anything, e.g. augmentation\n",
        "    transforms.Resize(160),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "train_data = celebADataset('train', transform)\n",
        "val_data = celebADataset('val', transform)\n",
        "test_data = celebADataset('test', transform)\n",
        "\n",
        "train_mean_data = celebADataset('train', transform, False)\n",
        "val_mean_data = celebADataset('val', transform, False)\n",
        "test_mean_data = celebADataset('test', transform, False)\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "train_mean_loader = torch.utils.data.DataLoader(train_mean_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_mean_loader = torch.utils.data.DataLoader(val_mean_data, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "test_mean_loader = torch.utils.data.DataLoader(test_mean_data, batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "tP_4urPR4871"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import inception_resnet_v1\n",
        "\n",
        "model = inception_resnet_v1.InceptionResnetV1(pretrained='vggface2')\n",
        "# model = inception_resnet_v1.InceptionResnetV1()\n",
        "\n",
        "model.conv2d_1a.requires_grad_(False)\n",
        "model.conv2d_2b.requires_grad_(False)\n",
        "model.maxpool_3a.requires_grad_(False)\n",
        "model.conv2d_3b.requires_grad_(False)\n",
        "model.conv2d_4a.requires_grad_(False)\n",
        "model.conv2d_4b.requires_grad_(False)\n",
        "\n",
        "model.repeat_1.requires_grad_(False)\n",
        "model.mixed_6a.requires_grad_(False)\n",
        "model.repeat_2.requires_grad_(False)\n",
        "# model.mixed_7a.requires_grad_(False)\n",
        "# model.repeat_3.requires_grad_(False)\n",
        "# model.block8.requires_grad_(False)\n"
      ],
      "metadata": {
        "id": "T7tRnSM75tSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_computing_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device\n",
        "\n",
        "\n",
        "device = get_computing_device()\n",
        "\n",
        "\n",
        "# triplet_loss = nn.TripletMarginWithDistanceLoss(distance_function=nn.PairwiseDistance())\n",
        "triplet_loss = nn.TripletMarginWithDistanceLoss(distance_function=lambda x, y: 1.0 - F.cosine_similarity(x, y))\n",
        "def compute_loss(anchor, positive, negative):\n",
        "    return triplet_loss(anchor, positive, negative)\n",
        "    # return F.cross_entropy(predictions, gt).mean()\n",
        "\n",
        "\n",
        "cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "def eval_model(model, data_t_generator, data_generator):\n",
        "    eps = 1e-5\n",
        "    accuracy = []\n",
        "    model.train(False)  # disable dropout / use averages for batch_norm\n",
        "    with torch.no_grad():\n",
        "        X = np.zeros((8544, 512))\n",
        "        y = np.zeros(8544)\n",
        "        for i, (anchor_img, anchor_label) in enumerate(data_t_generator):\n",
        "            anchor_img = anchor_img.to(device)\n",
        "            anchor_out = model(anchor_img)\n",
        "\n",
        "            l = i*len(anchor_img)\n",
        "            r = (i+1)*len(anchor_img)\n",
        "            X[l:r,:] = anchor_out.cpu().numpy()\n",
        "            y[l:r] = anchor_label.cpu().numpy()\n",
        "\n",
        "        neigh = KNeighborsClassifier(n_neighbors=5)\n",
        "        neigh.fit(X, y)\n",
        "\n",
        "        for i, (anchor_img, anchor_label) in enumerate(data_generator):\n",
        "            anchor_img = anchor_img.to(device)\n",
        "            anchor_out = model(anchor_img)\n",
        "\n",
        "            y_pred = neigh.predict(anchor_out.cpu().numpy())\n",
        "            accuracy.append(np.mean((anchor_label.cpu().numpy() == y_pred)))\n",
        "\n",
        "    return np.mean(accuracy)\n",
        "\n",
        "\n",
        "def train_model(model, optimizer, train_data_generator):\n",
        "    train_loss = []\n",
        "    model.train(True)  # enable dropout / batch_norm training behavior\n",
        "    for (anchor_img, anchor_label) in tqdm.tqdm(train_data_generator):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        anchor_img = anchor_img.to(device)\n",
        "        # positive_img = positive_img.to(device)\n",
        "        # negative_img = negative_img.to(device)\n",
        "\n",
        "        anchor_out = model(anchor_img)\n",
        "        # positive_out = model(positive_img)\n",
        "        # negative_out = model(negative_img)\n",
        "\n",
        "        # loss = compute_loss(anchor_out, positive_out, negative_out)\n",
        "\n",
        "        hard_pairs = miner(anchor_out, anchor_label)\n",
        "        loss = loss_func(anchor_out, anchor_label, hard_pairs)\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # metrics\n",
        "        train_loss.append(loss.cpu().data.numpy())\n",
        "    return np.mean(train_loss)\n",
        "\n",
        "\n",
        "def train_loop(model, optimizer, scheduler, train_data_generator, train_eval_data_generator, val_data_generator, num_epochs):\n",
        "    \"\"\"\n",
        "    num_epochs - total amount of full passes over training data\n",
        "    \"\"\"\n",
        "    best_accuracy = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        train_loss = train_model(model, optimizer, train_data_generator)\n",
        "\n",
        "        val_accuracy = eval_model(model, train_eval_data_generator, val_data_generator)\n",
        "\n",
        "        scheduler.step(val_accuracy)\n",
        "\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            # torch.save(model.state_dict(), 'best_model_weights2.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': val_accuracy\n",
        "            }, 'best_model_weights_triplet.pth')\n",
        "\n",
        "        # Then we print the results for this epoch:\n",
        "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
        "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n",
        "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(val_accuracy * 100))\n"
      ],
      "metadata": {
        "id": "D7CGBmOH550q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Our main computing device is '{device}'\")\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# checkpoint = torch.load('best_model_weights_triplet.pth')\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "\n",
        "from pytorch_metric_learning.distances import CosineSimilarity\n",
        "from pytorch_metric_learning.reducers import ThresholdReducer\n",
        "from pytorch_metric_learning.regularizers import LpRegularizer\n",
        "from pytorch_metric_learning import miners, losses\n",
        "miner = miners.MultiSimilarityMiner()\n",
        "loss_func = losses.TripletMarginLoss(distance=CosineSimilarity(),\n",
        "                                         reducer=ThresholdReducer(high=0.3),\n",
        "                                         embedding_regularizer=LpRegularizer())\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, 'max', patience=2)\n",
        "\n",
        "\n",
        "train_loop(model, opt, scheduler, train_mean_loader, train_mean_loader, val_mean_loader, num_epochs=30)\n",
        "\n",
        "print(eval_model(model, train_mean_loader, test_mean_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzn_di4K6DEn",
        "outputId": "44919a21-79a2-4938-cc7f-0e03dc1fda02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our main computing device is 'cuda:0'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 25/267 [00:04<00:38,  6.35it/s]"
          ]
        }
      ]
    }
  ]
}